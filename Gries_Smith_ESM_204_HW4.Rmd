---
title: "ESM 204 - Assignment 4"
author: "Conner Smith and Taylor Gries"
date: "5/18/2022"
output:
  html_document:
   theme:
     bg: "#002B36"
     fg: "#EEE8D5"
     primary: "#2AA198"
   code_folding: hide
   
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, options(scipen = 999))

library(tidyverse)
library(here)
library(janitor)
library(thematic)
library(scales)
library(equatiomatic)
library

thematic::thematic_rmd()
thematic::thematic_on()

```


## Overview

```{r}
# Read in the main data sets

damages <- read_csv(here("data", "damages.csv")) %>% 
  clean_names() 

warming <- read_csv(here("data", "warming.csv")) %>% 
  clean_names() %>% 
  select(-x1)

```


The federal government uses a variety of measures to estimate the SCC to quantify the costs associated with climate change. This analysis considers several discount rate calculation methods and reports differences in damages based on different warming and policy scenarios. 

## **Analysis** {.tabset}

The dataset contains the following:

- Climate change damages measured in USD based on warming increases in Degrees Celsius “high” and “low.” 
- Two warming scenarios (in Celsius) based on a "baseline" and "pulse" scenario with higher warming in the "pulse" scenario. 


### **1. Damage Equation**

This section generates a quadratic damage function relating the dollar value of damages to the change in global mean temperature.

```{r}
# Estimate a function with 0 intercept, take a look at the data first 

#ggplot(data = damages, aes(x = warming, y = damages)) +
  #geom_point()

# This is clearly exponential, create a vector of the warming values squared 

#Creating a scaled dataset scaled to billions 

damages_scale <- damages %>% 
  mutate(damages = damages/1000000000)

warming_square <- damages_scale$warming^2

# now we regress, force the itnercept to 0

damage_model <- lm(damages ~ 0 + warming + warming_square, data = damages_scale)
#summary(damage_model)
# This gives us an R^2 of 99%, we're good 

# summary essentially gives us that damages = 19409275730643(warming_square) -1059530137756(warming)
# Lets see if this makes sense when predicting 

warming_range <- damages$warming
damage_predict <- predict(damage_model,list(warming = warming_range, warming2 = warming_range^2))

# Create a function of the equation 

damage_function <- function(x){
  damage_model$coefficients[1]*x+damage_model$coefficients[2]*x^2
}
```

#### **Figure 1: Damages Resulting from Climate Change**

```{r}
# Plot the function along with the underlying data

  
ggplot(data = damages_scale, aes(x = warming, y = damages)) +
  geom_point(color = 'darkseagreen') +
  geom_smooth(aes(x = warming_range, y = damage_predict), color = 'sienna') +
  labs(x = 'Warming (Degrees Celsius)', y = 'Damages ($ billions)')

#Looks good enough to me, note the Y axis now shows damages in billions of dollars

```

### **2. Damage Calculations**

This section uses the function generated from the damages data to predict damages in each year under the baseline climate and the pulse scenario.

#### **Figure 2: Damages Over Time With and Without the "Pulse" Scenario**

```{r}
# Generate the estimates and facet wrap a plot showing the impacts of the two scenarios side by side 

#divide difference by 35 billion to get the effect per ton, note we already scaled to billions

pulse_ton <- 35

damages_predict <- warming %>%
  mutate(damages_baseline = damage_function(warming_baseline)) %>%
  mutate(damages_pulse = damage_function(warming_pulse)) %>%
  mutate(damages_difference = damages_pulse - damages_baseline) %>%
  mutate(damages_difference_ton = damages_difference/pulse_ton)

# Create the first graph showing the lines for both scenarios and total damages 

ggplot(data = damages_predict, aes(x = year)) +
  geom_smooth(aes(y = damages_baseline), color = "goldenrod") +
  geom_smooth(aes(y = damages_pulse), color = "sienna") +
  labs(x = 'Year', y = 'Damages ($ billions)')

```

*Note: the difference in damages between the two scenarios appear relatively small and the "pulse scenario" (red line) is only marginally higher than the "baseline" scenario (yellow line)*

#### **Figure 3: Difference in Absolute and Per Ton Damages Over Time Between Scenarios**

```{r}
# Generate the differences and facet wrap two plots showing absolute difference between the two scenarios and the difference per ton of CO2 

absolute_plot <- ggplot(data = damages_predict,
                        aes(x = year, y = damages_difference)) +
  geom_smooth(color = "goldenrod") +
  labs(x = 'Year', y = 'Difference in Damages ($ billions)')
absolute_plot

ton_plot <- ggplot(data = damages_predict,
                        aes(x = year, y = damages_difference_ton)) +
  geom_smooth(color = "sienna") +
  labs(x = 'Year', y = 'Difference in Damages ($ billions per ton)')
ton_plot


# may need to double check units/conversion here but the graphs look okay 

```

### **3. SCC Analysis**

This section uses different discount rates to estimate a range of potential SCC values.

#### **Figure 4: Discount Rate Impacts on SCC**

```{r}
# Plot a range of discount rates (likely 2-10 percent) to estimate SCC values 

# Calculate net damages up to 2100 from one tonne of CO2 by summing damages_difference_ton

net_damages_per_ton <- sum(damages_predict$damages_difference_ton)

# Create a function of net present value using the discount rate, damage, time, and present time

discount_damages <- function(rate, damage, time, present_time){
  NPV <- damage/ (1 + (rate/100))^(time-present_time)
  return(NPV)
}

# Create data frame for discounting

discount <- data_frame(rates = seq(0,10, 0.5), SCC = seq(0,10, 0.5))

# Use for loop to calculate the discounted damages up to 2100 for discount rates from 0 to 10 and apply function to sum all elements in column to find the net discounted cost

for(x in 1:length(discount$rates)){
  discount$SCC[x] <- sum(discount_damages(discount$rates[x], damages_predict$damages_difference_ton, damages_predict$year, 2022))
}

# Plot discount

ggplot(data = discount) +
  geom_point(aes(x = rates, y = SCC), color = "darkseagreen") + 
  labs (x = "Discount Rates (%)", y = "Social Cost of Carbon ($/ton)")

```

*Figure 4 shows that increasing the discount rate lowers the SCC*

### **4. Ramsey Rule**

This section uses the following function to estimate the SCC:

\begin{equation}
r=p+ng
\end{equation}

#### **Figure 5: The NPV of future damages between 2021 and 2100 at year 2021 discounted with respect to various discount rates. The coral point shows the discount rate and SCC associated with recommendations made by The National Academies of Sciences, Engineering, and Medicine**


```{r}
# Using ρ = 0.001, η = 2, and g = 0.01, what is the SCC, find it on the graph above 

# define the values 
p <- 0.001
n <- 2
g <- 0.01

# plug into the Ramsey rule

ramsey <- (p+n*g)*100

# plug into previous equation

discount_ramsey <- sum(discount_damages(ramsey,damages_predict$damages_difference_ton, damages_predict$year, 2022))

# SCC is $71.35 using the Ramsey Rule 

ggplot(data = discount)+
  geom_point(aes(x = rates, y = SCC), color = "darkseagreen")+
  geom_point(x = ramsey, y = discount_ramsey, color = "coral", size = 4) +
  geom_vline(xintercept = 2.1, color = 'darkseagreen', linetype = "dashed") +
  geom_label(aes(x = 4, label = "Ramsey Rule: SCC = $71.35",
                 y = 71), color = "darkseagreen", angle = 90) +
  labs(x = "Discount Rates (%)", y = "Social Cost of Carbon ($/ton)")

```

### **5. Policy Considerations**

This section will consider business as usual (Policy A) against strong action against climate change (Policy B). Conditions are as follows: 

- **Policy A:** Warming will occur as in the “baseline” (i.e. “no-pulse”) dataset above (this happens with probability 0.5) or warming each year will be 1.5 times that in the “baseline” dataset (with probability 0.5). 

- **Policy B:** Warming will continue until 2050 as in the “baseline” dataset, and then will stabilize at 1.29 degrees and stay that way forever. 

*Assume: Society is risk neutral and the discount rate is 2%. Policy A costs $0 and Policy B costs $X to implement. Total cost is implementation cost + damages.*

#### **Figure 6: Total Cost by Policy Pathway**

```{r}
# Estimate PV for the Policy A scenario, discount rate is 2%
discount_policy <- 2

# Need to create a new dataset with the damages and PV for both baseline and 1.5X warming 

damages_policy_a <- damages_predict %>% 
  select(year, warming_baseline, damages_baseline) %>%
  mutate(damages_1.5 = damage_function(1.5*warming_baseline)) %>%
  mutate(pv_baseline =
           discount_damages(discount_policy, damages_baseline,
                            damages_predict$year, 2022)) %>%
  mutate(pv_1.5 = discount_damages(discount_policy, damages_1.5,
                            damages_predict$year, 2022))

# Now we need to calculate the probabilities. 

prob_base <- 0.5
prob_1.5 <- 0.5

# Sum the pv for each 
sum_base <- sum(damages_policy_a$pv_baseline)
sum_1.5 <- sum(damages_policy_a$pv_1.5)

# Scale these by probability
expected_value_a <- (sum_base * prob_base) + (sum_1.5 * prob_1.5)
#3023245 billion dollars (I think) CHECK THIS NUMBER 

# Now do this for policy B
damages_policy_b <- damages_predict %>% 
  select(year, warming_baseline) 

for (i in 30:79){
  damages_policy_b$warming_baseline[i]=1.29
}

# Warming locked at 1.29 after 2050

damages_policy_b <- damages_policy_b %>% 
  mutate(damages_b = damage_function(warming_baseline)) %>%
  mutate(pv_b =
           discount_damages(discount_policy, damages_b,
                            damages_predict$year, 2022))

prob_b <- 1
sum_b <- sum(damages_policy_b$pv_b)  
expected_value_b <- (sum_b * prob_b)
```

- **A: Present Value of Damages under Policy A =** $`r round(expected_value_a, 0)` billion

- **B: Present Value of Damages under Policy B =** $`r round(expected_value_b, 0)` billion

*Based on total cost, Congress should implement Policy ?*

### **6. Risk Averse**

Now suppose that society is risk averse. How do you think this would change your advice to Congress?